{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f7e9a7-17fd-4946-b078-980d411bf22f",
   "metadata": {},
   "source": [
    "# Calculus and Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd158d1e-d35d-4d3f-bde7-82ebf9a9e1eb",
   "metadata": {},
   "source": [
    "## Polynomials and calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5da8e-22ff-41ae-81c6-30c23cb329b9",
   "metadata": {},
   "source": [
    "A [polynomial](https://mathworld.wolfram.com/Polynomial.html) is a mathematical expression involving a sum of powers in one or more variables multiplied by coefficients. A polynomial in one variable (i.e., a univariate polynomial) with constant coefficients is given by\n",
    "\n",
    "$$\n",
    "a_n \\, x^n + a_{n-1} \\, x^{n-1} + \\cdots + a_2 \\, x^2 + a_1 \\, x + a_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740aea2e-d068-42b9-9fb0-9c19b5690fd2",
   "metadata": {},
   "source": [
    "Calculus concerns the *differentiation* and *integration* of functions. Geometrically,\n",
    "\n",
    "- the *derivative*, obtained by *differentiating*, of a function is its *gradient*\n",
    "- the *integral*, obtained by *integrating*, of a function is the area that lies between the curve of the function and the $x$ axis, accounting for whether the curve lies above or below the axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287bdef-3a48-4da1-9fff-278aeb01fb55",
   "metadata": {},
   "source": [
    "### Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92f60c-d78f-4e02-8ddf-64c07116e342",
   "metadata": {},
   "source": [
    "For powers of a variable $x$, the rule for differentiation is to multiply by the power and reduce the power by 1, so that\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}x}\\,x^n = n \\, x^{n-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb4186-970f-4768-85ea-4d39e9f33172",
   "metadata": {},
   "source": [
    "The [derivative](https://mathworld.wolfram.com/Derivative.html) of a function $f$ with respect to the variable $x$, denoted either $f'(x)$ or $\\displaystyle\\frac{\\mathrm{d}f}{\\mathrm{d}x}$, is defined as\n",
    "\n",
    "$$\n",
    "f'(x) \\equiv \\lim\\limits_{h \\to 0} \\frac{f(x+h)-f(x)}{h}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c7ee1-7483-49de-a5f1-92ec7011cac5",
   "metadata": {},
   "source": [
    "Derivatives of sums are equal to the sum of derivatives so that\n",
    "\n",
    "$$\n",
    "\\{f + \\cdots + h \\}' = f' + \\cdots + h'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047eae8-b867-4061-9356-c851bb665e8c",
   "metadata": {},
   "source": [
    "If $c$ is a constant,\n",
    "\n",
    "$$\n",
    "\\{ c\\,f \\}' = c\\,f'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68535e6d-31be-46f4-931b-781b2f8b092d",
   "metadata": {},
   "source": [
    "The *product rule for differentiation* states that\n",
    "$\\{ fg \\}' = fg' + f'g$.\n",
    "Since $\\displaystyle\\lim\\limits_{h \\to 0} f(x+h) = f(x)$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\{ fg \\}\n",
    "& = \\lim\\limits_{h \\to 0} \\frac{f(x+h) g(x+h) - f(x) g(x)}{h} \\\\\n",
    "& = \\lim\\limits_{h \\to 0} \\frac{f(x+h) g(x+h) -f(x+h) g(x) + f(x+h) g(x) - f(x) g(x)}{h} \\\\\n",
    "& = \\lim\\limits_{h \\to 0} f(x+h) \\frac{g(x+h) - g(x)}{h}\n",
    "  + \\lim\\limits_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\\, g(x) \\\\\n",
    "& = f\\frac{\\mathrm{d} g}{\\mathrm{d} x} + \\frac{\\mathrm{d} f}{\\mathrm{d} x} g\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ffbc9-4073-4e05-9cfb-63320de69808",
   "metadata": {},
   "source": [
    "Derivatives of some simple functions are:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\{ e^x \\}' & = e^x \\\\\n",
    "\\{ a^x \\}' & = (\\mathrm{ln}\\,a)\\,a^x \\\\\n",
    "\\{ \\mathrm{ln}\\,x \\}' & = 1/x \\\\\n",
    "\\{ \\sin x \\}' & = \\cos x \\\\\n",
    "\\{ \\cos x \\}' & = -\\sin x\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee4c21-b1f0-40b8-970c-9132a8284609",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade6fd2-80d6-4509-aed8-eea01ba73d5d",
   "metadata": {},
   "source": [
    "Integration is, roughly speaking, anti-differentiation, in the sense that first integrating and then differentiating yields the original function. For powers of a variable $x$, the rule for integration is to increase the power by 1 and divide by the new power, so that\n",
    "\n",
    "$$\n",
    "\\int x^{n-1} \\, \\mathrm{d}x = \\frac{x^n}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c71d1-2d1a-4332-9a49-9d0592f0e6ed",
   "metadata": {},
   "source": [
    "## SymPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9362d-3312-4135-a4bd-c6fb11db62c4",
   "metadata": {},
   "source": [
    "SymPy can perform differentiation and integration of symbolic functions.\n",
    "\n",
    "$$\n",
    "f(x) = (x^2 - 2 x)\\,e^{3-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47009e6-a85c-4fc5-8886-178f62ce13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33924a17-36d3-4d8f-b4d6-20d8106a722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sympy.symbols('x')\n",
    "f = (x**2 - 2*x)*sympy.exp(3-x)\n",
    "fp = sympy.simplify(sympy.diff(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43a8d7-71ec-4253-982b-ede43204897e",
   "metadata": {},
   "source": [
    "An expression for the derivative that `sympy.diff` returns is often not expressed in its simplest form, so we use the `sympy.simplify` routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65789c9d-d8d0-462b-af53-b369c7657c17",
   "metadata": {},
   "source": [
    "We can compare whether the result is correct, compared to the derivative computed by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b40ce96-f0ce-4a6e-a371-b4acec00943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2 = (2*x -2)*sympy.exp(3-x) - (x**2 - 2*x)*sympy.exp(3-x)\n",
    "assert sympy.simplify(fp2 - fp) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4dee8-37e2-4f8c-b861-480f9d8e7094",
   "metadata": {},
   "source": [
    "We can integrate the function, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38580dca-e262-4812-b762-84703d764d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = sympy.integrate(f, x)\n",
    "assert sympy.simplify(-x**2*sympy.exp(3-x) - F) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83398a9f-7e26-4eb3-a207-192927005124",
   "metadata": {},
   "source": [
    "The most important feature of SymPy is the ability to perform symbolic calculus &mdash; rather than the numerical calculus &mdash; and give exact (sometimes called *analytic*) solutions to calculus problems.\n",
    "\n",
    "You can also evaluate SymPy expressions numerically. This is done using the `lamdify` routine from the `sympy.utilities` modules. This converts a SymPy expression to a numerical expression that uses the NumPy equivalents of the SymPy standard function to evaluate the expression numerically. The result is similar to defining a Python Lambda, hence the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f51c14-cf9d-467e-bac4-070fdca3b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.utilities import lambdify\n",
    "lam_f = lambdify(x, f)\n",
    "lam_fp = lambdify(x, fp)\n",
    "\n",
    "import numpy as np\n",
    "assert np.isclose(lam_f(4), 2.9430355293715387)\n",
    "assert np.isclose(lam_fp(7), -0.4212596944408861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19befe-9a1b-4c15-8c60-9bbe58221c3d",
   "metadata": {},
   "source": [
    "## Solving equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde21d0-587b-4481-9ebf-015be381af3d",
   "metadata": {},
   "source": [
    "Many mathematical problems eventually reduce to solving an equation of the form $f(x)=0$, where $f$ is a function of a single variable $x$. Here, we try to find a value of $x$ for which the equation holds. The values of $x$ for which the equation holds are sometimes called *roots* of the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c22c8-26b9-4707-8442-a8f78ec4a330",
   "metadata": {},
   "source": [
    "We will use the function defined by\n",
    "\n",
    "$$\n",
    "f(x) = (x^2 - 2x)\\,e^{3-x}\n",
    "$$\n",
    "\n",
    "which is defined for all real values of $x$ and has exactly two roots, one at $x = 0$ and one at $x = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b3bf-a5f8-4c3f-bdde-4af2ff194bbc",
   "metadata": {},
   "source": [
    "The SciPy package contains routines for solving equations. The root finding routines can be found in the `optimize` module from the `scipy` package. If your equation is not in the form of $f(x) = 0$, then you will need to rearrange it so that this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3e3531-b3e2-4119-8f53-49835b1e26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2819a03-afc2-4492-838f-69207ef71ad5",
   "metadata": {},
   "source": [
    "The Newton-Raphson method (Newton's method) and the secant method are good, standard root finding algorithms that can be applied in almost any situation. These are *iterative* methods that start with an approximation of the root and iteratively improve this approximation until it lies within a given tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebec68-7155-48ca-bc5a-7d453fc6bc92",
   "metadata": {},
   "source": [
    "For both the Newton-Raphson and secant methods, we use the `newton` routine from `optimize`. Both the secant method and the Newton-Raphson method require the function as the first argument, and the first approximation as the second argument. To use the Newton-Raphson method, we must provide the derivative of the function, using the `fprime` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5318e74-46ea-4f0d-940e-ab9a937f21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert optimize.newton(lam_f, 1., fprime=lam_fp) == 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618ea6e-0a0a-4441-89f4-6196ce9e6e78",
   "metadata": {},
   "source": [
    "To use the secant method, only the function is needed, but we must provide the first two approximations for the root; the second is provided as the `x1` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0295f7d7-37f7-47ad-8026-522f6fa0434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = optimize.newton(lam_f, 1., x1=1.5)\n",
    "assert roots != 2.\n",
    "assert np.isclose(roots, 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f7499-5a2c-4232-b4c1-669ac12fa3c9",
   "metadata": {},
   "source": [
    "Broadly speaking, root finding algorithms fall into two categories:\n",
    "\n",
    "- algorithms that use information about the function's gradient at each iterate (Newton-Raphson, secant, Halley) and\n",
    "- algorithms that require bounds on the location of a root (bisection method, regula-falsi, Brent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5af2d-ec28-441a-be4e-38492da26d30",
   "metadata": {},
   "source": [
    "The Newton-Raphson method, one of the first kind, for a function $f(x)$ with derivative $f'(x)$ and initial approximation $x0$ is defined iteratively using the formula\n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i - \\frac{f(x_i)}{f'(x_i)}\n",
    "$$\n",
    "\n",
    "for each integer $i \\geq 0$. Geometrically, this formula arises by considering the direction in which the gradient is negative (so the function is decreasing) if $f(x_i) \\gt 0$ or positive (so the function is increasing) if $f(x_i) \\lt 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2c2f0-341b-44ad-ae17-647b919b5098",
   "metadata": {},
   "source": [
    "The second kind of algorithms are those for which a root is known to exist within a specified interval $a \\leq x \\leq b$. We can check whether a root lies within such an interval by checking that $f(a)$ and $f(b)$ have different signs, that is, one of $f(a) \\lt 0 \\lt f(b)$ or $f(b) \\lt 0 \\lt f(a)$ is true. (Provided, of course, that the function is *continuous*, which tends to be the case in practice.) &cdots; The basic premise is to split the interval between $a$ and $b$ at the mid-point and select the interval in which the function changes sign.\n",
    "\n",
    "Brent's method is an improvement on the bisection method, and is available in the `optimize` module as `brentq`. It uses a combination of bisection and interpolation to quickly find the root of an equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c2c75a-f04c-4599-b175-66831122c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = optimize.brentq(lam_f, 1.0, 3.0)\n",
    "assert roots != 2.\n",
    "assert np.isclose(roots, 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e840b-1147-44a3-b9f5-95d6dcc4cc86",
   "metadata": {},
   "source": [
    "## Integrating functions numerically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708fb01-2fec-46b8-ab4f-48853a142a32",
   "metadata": {},
   "source": [
    "Some integrals cannot be computed directly, using symbolic means, and instead have to be approximated numerically. One classic example of this is the Gaussian error function, which is defined as follows, and the integral that appear here cannot be evaluated symbolically:\n",
    "\n",
    "$$\n",
    "erf(x) = \\frac{1}{\\sqrt{\\pi}} \\int_{-x}^{x} e^{-t^2} \\mathrm{d}t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edffc8-df39-4989-8bae-cf1c4ab395c5",
   "metadata": {},
   "source": [
    "We use the `scipy.integrate` module, which contains several routines for computing numerical integrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255db6f3-7248-48e8-9589-0e96f45d4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250df5f6-047a-4918-9cf0-f63b5942a7d6",
   "metadata": {},
   "source": [
    "We need to define the integrand (the function that appears inside the integral) in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5816f8da-ee0c-4031-b14b-8491f8c59fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erf_integrand(t):\n",
    "    return np.exp(-t**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cad1b-7655-4497-8456-343e48269a04",
   "metadata": {},
   "source": [
    "There are two main routines in `scipy.integrate` for performing numerical integration (quadrature) that can be used. The first is the `quad` function, which uses QUADPACK to perform the integration, and the second is `quadrature`.\n",
    "\n",
    "> `scipy.integrate.quadrature` is deprecated as of SciPy 1.12.0 and will be removed in SciPy 1.15.0. Please use`scipy.integrate.quad` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec1981-00c0-45d1-bea4-c448fe25e248",
   "metadata": {},
   "source": [
    "The `quad` routine is a general-purpose integration tool. It expects three arguments, which are the function to be integrated (`erf_integrand`), the lower limit ($-1.0$), and the upper limit ($1.0$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb43bacc-44f7-4442-a5ee-e1391c55c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "val, err = integrate.quad(erf_integrand, -1., 1.)\n",
    "assert np.isclose(val, 1.493648265624854)\n",
    "assert np.isclose(err, 1.6582826951881447e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4e24f-4359-477d-ae87-847833a8340e",
   "metadata": {},
   "source": [
    "The first returned value is the value of the integral and the second is an estimate for the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc693218-3ec0-4cc0-8f9d-1f2d2f16ceb5",
   "metadata": {},
   "source": [
    "Most numerical integration techniques follow the same basic procedure. First, we choose points $x_i$ for $i = 1, 2, \\dots, n$ in the region of integration, and then use these values and the values $f(x_i)$ to approximate the integral. For example, with the trapezium rule, we approximate the integral by\n",
    "\n",
    "$$\n",
    "\\int_{a}^{b} f(x) \\mathrm{d}x \\approx\n",
    "\\frac{h}{2} \\left( f(a)+f(b)+2 \\sum_{j=1}^{n-1}f(x_i) \\right)\n",
    "$$\n",
    "\n",
    "where $a \\lt x_1 \\lt x_2 \\lt \\dots \\lt x_{n-1} \\lt b$, and $h$ is the (common) difference between adjacent $x_i$ values, including the end points $a$ and $b$, i.e., $h = (b-a)/n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b34ec-df22-4d34-b6c3-b54eb2d77486",
   "metadata": {},
   "source": [
    "The routines mentioned in this section require the integrand function to be known, which is not always the case. Instead, it might be the case that we know a number of pairs `(x,y)` with $y = f(x)$, but we don't know the function $f$ to evaluate at additional points. In this case, we can use one of the sampling quadrature techniques from `scipy.integrate`.\n",
    "\n",
    "- the `romb` routine that follows Romberg integration\n",
    "- the `trapz` routine that follows the trapezium rule\n",
    "- the `simps` routine that follows the Simpson's rule\n",
    "\n",
    "If the number of known points is very large and all points are equally spaced, we can use Romberg integration for a good approximation of the integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef442ec-bc62-4a64-8e52-ef468828dc12",
   "metadata": {},
   "source": [
    "## Solving simple differential equation numerically"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
